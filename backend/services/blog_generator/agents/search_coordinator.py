"""
SearchCoordinator Agent - æœç´¢åè°ƒå™¨
è´Ÿè´£ç®¡ç†å¤šè½®æœç´¢ã€æ£€æµ‹çŸ¥è¯†ç©ºç™½ã€æ‰§è¡Œç»†åŒ–æœç´¢
"""

import json
import logging
import os
from typing import Dict, Any, List, Optional

from ..prompts import get_prompt_manager
from ..schemas.state import get_max_search_count

logger = logging.getLogger(__name__)


class SearchCoordinator:
    """
    æœç´¢åè°ƒå™¨ - ç®¡ç†å¤šè½®æœç´¢

    èŒè´£ï¼š
    1. ç®¡ç†æœç´¢æ¬¡æ•°å’Œé…é¢
    2. æ£€æµ‹çŸ¥è¯†ç©ºç™½
    3. æ„é€ ç»†åŒ–æŸ¥è¯¢
    4. æ•´åˆå¤šè½®æœç´¢ç»“æœ
    """

    def __init__(self, llm_client, search_service):
        """
        åˆå§‹åŒ–æœç´¢åè°ƒå™¨

        Args:
            llm_client: LLM å®¢æˆ·ç«¯
            search_service: æœç´¢æœåŠ¡
        """
        self.llm = llm_client
        self.search_service = search_service

        # 75.04 çŸ¥è¯†ç©ºç™½æ£€æµ‹å™¨ï¼ˆå¯é€‰å¢å¼ºï¼‰
        self._gap_detector = None
        if os.environ.get('KNOWLEDGE_GAP_DETECTOR_ENABLED', 'false').lower() == 'true':
            try:
                from ..services.knowledge_gap_detector import KnowledgeGapDetector
                self._gap_detector = KnowledgeGapDetector(llm_service=llm_client)
                logger.info("ğŸ” çŸ¥è¯†ç©ºç™½æ£€æµ‹å™¨å·²å¯ç”¨ (75.04)")
            except Exception as e:
                logger.warning(f"çŸ¥è¯†ç©ºç™½æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def can_search(self, state: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦è¿˜èƒ½ç»§ç»­æœç´¢"""
        current = state.get('search_count', 0)
        max_count = state.get('max_search_count', 5)
        return current < max_count
    
    def detect_knowledge_gaps(
        self,
        content: str,
        existing_knowledge: str,
        context: str = "",
        topic: str = ""
    ) -> List[Dict[str, Any]]:
        """
        æ£€æµ‹çŸ¥è¯†ç©ºç™½
        
        Args:
            content: å½“å‰å†…å®¹
            existing_knowledge: å·²æœ‰èƒŒæ™¯çŸ¥è¯†
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            topic: æŠ€æœ¯ä¸»é¢˜
            
        Returns:
            çŸ¥è¯†ç©ºç™½åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å«:
            - gap_type: "missing_data" | "vague_concept" | "no_example"
            - description: ç©ºç™½æè¿°
            - suggested_query: å»ºè®®çš„æœç´¢æŸ¥è¯¢
        """
        pm = get_prompt_manager()
        prompt = pm.render_knowledge_gap_detector(
            content=content,
            existing_knowledge=existing_knowledge,
            context=context,
            topic=topic
        )
        
        try:
            response = self.llm.chat(
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response)
            gaps = result.get('gaps', [])
            
            logger.info(f"æ£€æµ‹åˆ° {len(gaps)} ä¸ªçŸ¥è¯†ç©ºç™½")
            for gap in gaps:
                logger.debug(f"  - [{gap.get('gap_type')}] {gap.get('description')}")
            
            return gaps
            
        except Exception as e:
            logger.error(f"çŸ¥è¯†ç©ºç™½æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def refine_search(
        self,
        gaps: List[Dict[str, Any]],
        state: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œç»†åŒ–æœç´¢
        
        Args:
            gaps: çŸ¥è¯†ç©ºç™½åˆ—è¡¨
            state: å½“å‰çŠ¶æ€
            
        Returns:
            æœç´¢ç»“æœå­—å…¸ï¼ŒåŒ…å«:
            - success: æ˜¯å¦æˆåŠŸ
            - results: æœç´¢ç»“æœåˆ—è¡¨
            - new_knowledge: æ–°å¢çŸ¥è¯†æ‘˜è¦
        """
        if not self.can_search(state):
            logger.warning("å·²è¾¾åˆ°æœ€å¤§æœç´¢æ¬¡æ•°ï¼Œæ— æ³•ç»§ç»­æœç´¢")
            return {
                "success": False,
                "reason": "å·²è¾¾åˆ°æœ€å¤§æœç´¢æ¬¡æ•°",
                "results": []
            }
        
        if not gaps:
            logger.info("æ²¡æœ‰çŸ¥è¯†ç©ºç™½éœ€è¦è¡¥å……")
            return {
                "success": True,
                "results": [],
                "new_knowledge": ""
            }
        
        all_results = []
        queries_used = []
        gaps_addressed = []
        
        # æ¯è½®æœ€å¤šå¤„ç†2ä¸ªç©ºç™½ç‚¹ï¼Œé¿å…æœç´¢è¿‡å¤š
        for gap in gaps[:2]:
            query = gap.get('suggested_query', '')
            if not query:
                continue
            
            logger.info(f"æ‰§è¡Œç»†åŒ–æœç´¢: {query}")
            queries_used.append(query)
            gaps_addressed.append(gap.get('description', ''))
            
            try:
                result = self.search_service.search(query, max_results=3)
                if result.get('success'):
                    all_results.extend(result.get('results', []))
            except Exception as e:
                logger.error(f"æœç´¢å¤±è´¥ [{query}]: {e}")
        
        # æ›´æ–°æœç´¢è®¡æ•°
        current_count = state.get('search_count', 0)
        state['search_count'] = current_count + 1
        
        # è®°å½•æœç´¢å†å²
        search_history = state.get('search_history', [])
        search_history.append({
            'round': current_count + 1,
            'queries': queries_used,
            'results_count': len(all_results),
            'gaps_addressed': gaps_addressed
        })
        state['search_history'] = search_history
        
        # å»é‡æœç´¢ç»“æœ
        unique_results = self._deduplicate_results(all_results)
        
        # ç”Ÿæˆæ–°çŸ¥è¯†æ‘˜è¦
        new_knowledge = self._summarize_results(unique_results, gaps)
        
        # ç´¯ç§¯çŸ¥è¯†
        accumulated = state.get('accumulated_knowledge', '')
        if new_knowledge:
            state['accumulated_knowledge'] = accumulated + "\n\n" + new_knowledge if accumulated else new_knowledge
        
        logger.info(f"ç»†åŒ–æœç´¢å®Œæˆ: ç¬¬ {current_count + 1} è½®, è·å– {len(unique_results)} æ¡ç»“æœ")
        
        return {
            "success": True,
            "results": unique_results,
            "new_knowledge": new_knowledge
        }
    
    def _deduplicate_results(self, results: List[Dict]) -> List[Dict]:
        """å»é‡æœç´¢ç»“æœ"""
        seen_urls = set()
        unique = []
        
        for result in results:
            url = result.get('url', '')
            if url and url not in seen_urls:
                seen_urls.add(url)
                unique.append(result)
        
        return unique
    
    def _summarize_results(
        self,
        results: List[Dict],
        gaps: List[Dict]
    ) -> str:
        """
        å°†æœç´¢ç»“æœæ‘˜è¦ä¸ºçŸ¥è¯†æ–‡æœ¬
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            gaps: åŸå§‹çŸ¥è¯†ç©ºç™½
            
        Returns:
            çŸ¥è¯†æ‘˜è¦æ–‡æœ¬
        """
        if not results:
            return ""
        
        # ä½¿ç”¨æ¨¡æ¿æ¸²æŸ“ prompt
        pm = get_prompt_manager()
        prompt = pm.render_search_summarizer(gaps=gaps, results=results)
        
        try:
            response = self.llm.chat(
                messages=[{"role": "user", "content": prompt}]
            )
            return response.strip()
        except Exception as e:
            logger.error(f"çŸ¥è¯†æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            # é™çº§ï¼šç›´æ¥æ‹¼æ¥ç»“æœå†…å®¹
            return "\n".join([r.get('content', '')[:200] for r in results[:3]])
    
    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡ŒçŸ¥è¯†ç©ºç™½æ£€æŸ¥å’Œç»†åŒ–æœç´¢
        
        Args:
            state: å…±äº«çŠ¶æ€
            
        Returns:
            æ›´æ–°åçš„çŠ¶æ€
        """
        if state.get('error'):
            logger.error(f"å‰ç½®æ­¥éª¤å¤±è´¥ï¼Œè·³è¿‡çŸ¥è¯†æ£€æŸ¥: {state.get('error')}")
            return state
        
        sections = state.get('sections', [])
        if not sections:
            logger.warning("æ²¡æœ‰ç« èŠ‚å†…å®¹ï¼Œè·³è¿‡çŸ¥è¯†æ£€æŸ¥")
            state['knowledge_gaps'] = []
            return state
        
        # åˆå¹¶æ‰€æœ‰ç« èŠ‚å†…å®¹
        all_content = "\n\n".join([
            f"## {s.get('title', '')}\n{s.get('content', '')}"
            for s in sections
        ])
        
        existing_knowledge = state.get('accumulated_knowledge', '') or state.get('background_knowledge', '')
        topic = state.get('topic', '')
        
        logger.info(f"å¼€å§‹çŸ¥è¯†ç©ºç™½æ£€æŸ¥ (å½“å‰æœç´¢æ¬¡æ•°: {state.get('search_count', 0)}/{state.get('max_search_count', 5)})")
        
        # æ£€æµ‹çŸ¥è¯†ç©ºç™½ï¼ˆ75.04 å¢å¼ºç‰ˆ or åŸæœ‰é€»è¾‘ï¼‰
        if self._gap_detector:
            outline = state.get('outline')
            gaps_raw = self._gap_detector.detect(
                search_results=state.get('search_results', []),
                topic=topic,
                outline=outline,
            )
            # è½¬æ¢ä¸º SearchCoordinator æ ¼å¼
            gaps = []
            for g in gaps_raw:
                gaps.append({
                    'gap_type': 'missing_data',
                    'description': g.get('gap', ''),
                    'suggested_query': g.get('refined_query', ''),
                })
            logger.info(f"[75.04] çŸ¥è¯†ç©ºç™½æ£€æµ‹å™¨å‘ç° {len(gaps)} ä¸ªç©ºç™½")
        else:
            gaps = self.detect_knowledge_gaps(
                content=all_content,
                existing_knowledge=existing_knowledge,
                context=f"æ–‡ç« ä¸»é¢˜: {topic}",
                topic=topic
            )
        
        state['knowledge_gaps'] = gaps
        
        return state
