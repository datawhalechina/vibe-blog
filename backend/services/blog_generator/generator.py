"""
é•¿æ–‡åšå®¢ç”Ÿæˆå™¨ - LangGraph å·¥ä½œæµä¸»å…¥å£
"""

import logging
import os
from typing import Dict, Any, Optional, Literal, Callable

from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import interrupt

from .schemas.state import SharedState, create_initial_state
from .style_profile import StyleProfile
from .agents.researcher import ResearcherAgent
from .agents.planner import PlannerAgent
from .agents.writer import WriterAgent
from .agents.coder import CoderAgent
from .agents.artist import ArtistAgent
from .agents.questioner import QuestionerAgent
from .agents.reviewer import ReviewerAgent
from .agents.assembler import AssemblerAgent
from .agents.search_coordinator import SearchCoordinator
from .agents.humanizer import HumanizerAgent
from utils.session_tracker import SessionTracker
from .agents.thread_checker import ThreadCheckerAgent
from .agents.voice_checker import VoiceCheckerAgent
from .agents.factcheck import FactCheckAgent
from .agents.summary_generator import SummaryGeneratorAgent
from .middleware import (
    MiddlewarePipeline, TracingMiddleware, ReducerMiddleware,
    ErrorTrackingMiddleware, TokenBudgetMiddleware, ContextPrefetchMiddleware,
    TaskLogMiddleware,
    ErrorTrackingMiddleware, TokenBudgetMiddleware, ContextPrefetchMiddleware,
)
from .context_management_middleware import ContextManagementMiddleware
from .parallel import ParallelTaskExecutor, TaskConfig
from .llm_proxy import TieredLLMProxy
from .llm_tier_config import get_agent_tier
import uuid

logger = logging.getLogger(__name__)


def _get_content_word_count(state: Dict[str, Any]) -> int:
    """è®¡ç®—å½“å‰ state ä¸­æ‰€æœ‰ç« èŠ‚å†…å®¹çš„æ€»å­—æ•°"""
    sections = state.get('sections', [])
    total = 0
    for section in sections:
        content = section.get('content', '')
        if content:
            total += len(content)
    return total


def _log_word_count_diff(agent_name: str, before: int, after: int):
    """è®°å½•å­—æ•°å˜åŒ–çš„ diff"""
    diff = after - before
    if diff >= 0:
        logger.info(f"ğŸ“Š [{agent_name}] å­—æ•°å˜åŒ–: {before} â†’ {after} (+{diff} å­—)")
    else:
        logger.info(f"ğŸ“Š [{agent_name}] å­—æ•°å˜åŒ–: {before} â†’ {after} ({diff} å­—)")


class BlogGenerator:
    """
    é•¿æ–‡åšå®¢ç”Ÿæˆå™¨
    
    åŸºäº LangGraph å®ç°çš„ Multi-Agent ååŒç”Ÿæˆç³»ç»Ÿ
    """
    
    def __init__(
        self,
        llm_client,
        search_service=None,
        knowledge_service=None,
        max_questioning_rounds: int = 2,
        max_revision_rounds: int = 3,
        style: StyleProfile = None
    ):
        """
        åˆå§‹åŒ–åšå®¢ç”Ÿæˆå™¨

        Args:
            llm_client: LLM å®¢æˆ·ç«¯
            search_service: æœç´¢æœåŠ¡ (å¯é€‰)
            knowledge_service: çŸ¥è¯†æœåŠ¡ (å¯é€‰ï¼Œç”¨äºæ–‡æ¡£çŸ¥è¯†èåˆ)
            max_questioning_rounds: æœ€å¤§è¿½é—®è½®æ•°
            max_revision_rounds: æœ€å¤§ä¿®è®¢è½®æ•°
            style: é£æ ¼é…ç½®ï¼ˆå¯é€‰ï¼Œä¸ä¼ åˆ™ä»ç¯å¢ƒå˜é‡æ„å»ºé»˜è®¤å€¼ï¼‰
        """
        self.llm = llm_client
        self.search_service = search_service
        self.knowledge_service = knowledge_service
        self.max_questioning_rounds = max_questioning_rounds
        self.style = style  # å»¶è¿Ÿåˆå§‹åŒ–ï¼šgenerate() æ—¶æ ¹æ® target_length ç¡®å®š

        # max_revision_rounds å‘åå…¼å®¹ï¼šä¼˜å…ˆç”¨ StyleProfileï¼Œå¦åˆ™ç”¨å‚æ•°
        self.max_revision_rounds = max_revision_rounds

        # åˆå§‹åŒ–å„ Agentï¼ˆ41.06: é€šè¿‡ TieredLLMProxy æŒ‰çº§åˆ«è·¯ç”±æ¨¡å‹ï¼‰
        def _proxy(agent_name):
            return TieredLLMProxy(llm_client, get_agent_tier(agent_name))

        self.researcher = ResearcherAgent(_proxy('researcher'), search_service, knowledge_service)
        self.planner = PlannerAgent(_proxy('planner'))
        self.writer = WriterAgent(_proxy('writer'))
        self.coder = CoderAgent(_proxy('coder'))
        self.artist = ArtistAgent(_proxy('artist'))
        self.questioner = QuestionerAgent(_proxy('questioner'))
        self.reviewer = ReviewerAgent(_proxy('reviewer'))
        self.assembler = AssemblerAgent()
        self.search_coordinator = SearchCoordinator(_proxy('search_coordinator'), search_service)

        # å¢å¼º Agentï¼šç¯å¢ƒå˜é‡ä½œä¸ºå…¨å±€å¼€å…³ï¼ˆStyleProfile ä½œä¸ºè¿è¡Œæ—¶å¼€å…³ï¼‰
        self._env_humanizer = os.getenv('HUMANIZER_ENABLED', 'true').lower() == 'true'
        self._env_thread_check = os.getenv('THREAD_CHECK_ENABLED', 'true').lower() == 'true'
        self._env_voice_check = os.getenv('VOICE_CHECK_ENABLED', 'true').lower() == 'true'
        self._env_factcheck = os.getenv('FACTCHECK_ENABLED', 'true').lower() == 'true'
        self._env_text_cleanup = os.getenv('TEXT_CLEANUP_ENABLED', 'true').lower() == 'true'
        self._env_summary = os.getenv('SUMMARY_GENERATOR_ENABLED', 'true').lower() == 'true'

        # åˆå§‹åŒ–å¢å¼º Agentï¼ˆåªè¦ç¯å¢ƒå˜é‡æ²¡ç¦ç”¨å°±åˆ›å»ºå®ä¾‹ï¼‰
        self.humanizer = HumanizerAgent(_proxy('humanizer')) if self._env_humanizer else None
        self.thread_checker = ThreadCheckerAgent(_proxy('thread_checker')) if self._env_thread_check else None
        self.voice_checker = VoiceCheckerAgent(_proxy('voice_checker')) if self._env_voice_check else None
        self.factcheck = FactCheckAgent(_proxy('factcheck')) if self._env_factcheck else None

        # ä¸šåŠ¡çº§çŠ¶æ€è¿½è¸ªï¼ˆ69.05ï¼‰
        self.tracker = SessionTracker()
        self.summary_generator = SummaryGeneratorAgent(_proxy('summary_generator')) if self._env_summary else None

        # 37.12 åˆ†å±‚æ¶æ„æ ¡éªŒå™¨ï¼ˆå¯é€‰ï¼‰
        self._layer_validator = None
        if os.environ.get('LAYER_VALIDATION_ENABLED', 'false').lower() == 'true':
            try:
                from .orchestrator.layer_definitions import BLOG_LAYERS, LayerValidator
                self._layer_validator = LayerValidator(BLOG_LAYERS)
                logger.info("ğŸ—ï¸ åˆ†å±‚æ¶æ„æ ¡éªŒå·²å¯ç”¨")
            except Exception as e:
                logger.warning(f"åˆ†å±‚æ¶æ„æ ¡éªŒåˆå§‹åŒ–å¤±è´¥: {e}")

        # 102.10 è¿ç§»ï¼šä¸­é—´ä»¶ç®¡é“
        self._task_log_middleware = TaskLogMiddleware()
        self.pipeline = MiddlewarePipeline(middlewares=[
            TracingMiddleware(),
            self._task_log_middleware,
            ReducerMiddleware(),
            ErrorTrackingMiddleware(),
            ContextManagementMiddleware(
                llm_service=llm_client,
                model_name=os.getenv("LLM_MODEL", "gpt-4o"),
            ),
            TokenBudgetMiddleware(
                compressor=getattr(self, '_context_compressor', None),
                token_tracker=getattr(self, '_token_tracker', None),
            ),
            ContextPrefetchMiddleware(
                knowledge_service=knowledge_service,
            ),
        ])

        # 102.01 è¿ç§»ï¼šç»Ÿä¸€å¹¶è¡Œä»»åŠ¡æ‰§è¡Œå¼•æ“
        self.executor = ParallelTaskExecutor()

        # 102.06 è¿ç§»ï¼šå†™ä½œæ–¹æ³•è®ºæŠ€èƒ½ç®¡ç†å™¨
        self._writing_skill_manager = None
        if os.getenv('WRITING_SKILL_ENABLED', 'true').lower() == 'true':
            try:
                from .skills.writing_skill_manager import WritingSkillManager
                self._writing_skill_manager = WritingSkillManager()
                self._writing_skill_manager.load()
                logger.info("102.06 WritingSkillManager å·²å¯ç”¨")
            except Exception as e:
                logger.warning(f"WritingSkillManager åˆå§‹åŒ–å¤±è´¥: {e}")

        # 102.03 è¿ç§»ï¼šç”¨æˆ·è®°å¿†å­˜å‚¨
        self._memory_storage = None
        if os.getenv('MEMORY_ENABLED', 'false').lower() == 'true':
            try:
                from .memory import MemoryStorage, BlogMemoryConfig
                mem_config = BlogMemoryConfig.from_env()
                self._memory_storage = MemoryStorage(storage_path=mem_config.storage_path)
                logger.info("102.03 MemoryStorage å·²å¯ç”¨")
            except Exception as e:
                logger.warning(f"MemoryStorage åˆå§‹åŒ–å¤±è´¥: {e}")

        # æ„å»ºå·¥ä½œæµ
        self.workflow = self._build_workflow()
        self.app = None

    def _validate_layer(self, layer_name: str, state: Dict[str, Any]):
        """37.12 å±‚é—´æ•°æ®å¥‘çº¦æ ¡éªŒï¼ˆä»…æ—¥å¿—è­¦å‘Šï¼Œä¸é˜»æ–­æµç¨‹ï¼‰"""
        if not self._layer_validator:
            return
        try:
            ok, missing = self._layer_validator.validate_inputs(layer_name, state)
            if not ok:
                logger.warning(f"ğŸ—ï¸ [{layer_name}] å±‚è¾“å…¥ç¼ºå¤±: {missing}")
        except Exception as e:
            logger.debug(f"å±‚æ ¡éªŒå¼‚å¸¸: {e}")
    
    def _build_workflow(self) -> StateGraph:
        """
        æ„å»º LangGraph å·¥ä½œæµ
        
        Returns:
            StateGraph å®ä¾‹
        """
        workflow = StateGraph(SharedState)
        
        # æ·»åŠ èŠ‚ç‚¹ï¼ˆ102.10 è¿ç§»ï¼šé€šè¿‡ä¸­é—´ä»¶ç®¡é“åŒ…è£…ï¼‰
        workflow.add_node("researcher", self.pipeline.wrap_node("researcher", self._researcher_node))
        workflow.add_node("planner", self.pipeline.wrap_node("planner", self._planner_node))
        workflow.add_node("writer", self.pipeline.wrap_node("writer", self._writer_node))
        # å¤šè½®æœç´¢ç›¸å…³èŠ‚ç‚¹
        workflow.add_node("check_knowledge", self.pipeline.wrap_node("check_knowledge", self._check_knowledge_node))
        workflow.add_node("refine_search", self.pipeline.wrap_node("refine_search", self._refine_search_node))
        workflow.add_node("enhance_with_knowledge", self.pipeline.wrap_node("enhance_with_knowledge", self._enhance_with_knowledge_node))
        # è¿½é—®å’Œå®¡æ ¸èŠ‚ç‚¹
        workflow.add_node("questioner", self.pipeline.wrap_node("questioner", self._questioner_node))
        workflow.add_node("deepen_content", self.pipeline.wrap_node("deepen_content", self._deepen_content_node))
        workflow.add_node("coder_and_artist", self.pipeline.wrap_node("coder_and_artist", self._coder_and_artist_node))  # å¹¶è¡ŒèŠ‚ç‚¹
        workflow.add_node("cross_section_dedup", self.pipeline.wrap_node("cross_section_dedup", self._cross_section_dedup_node))  # 41.09 è·¨ç« èŠ‚å»é‡
        workflow.add_node("section_evaluate", self.pipeline.wrap_node("section_evaluate", self._section_evaluate_node))  # æ®µè½è¯„ä¼°
        workflow.add_node("section_improve", self.pipeline.wrap_node("section_improve", self._section_improve_node))  # æ®µè½æ”¹è¿›
        workflow.add_node("consistency_check", self.pipeline.wrap_node("consistency_check", self._consistency_check_node))  # ä¸€è‡´æ€§æ£€æŸ¥
        workflow.add_node("reviewer", self.pipeline.wrap_node("reviewer", self._reviewer_node))
        workflow.add_node("revision", self.pipeline.wrap_node("revision", self._revision_node))
        workflow.add_node("factcheck", self.pipeline.wrap_node("factcheck", self._factcheck_node))
        workflow.add_node("text_cleanup", self.pipeline.wrap_node("text_cleanup", self._text_cleanup_node))
        workflow.add_node("humanizer", self.pipeline.wrap_node("humanizer", self._humanizer_node))
        workflow.add_node("assembler", self.pipeline.wrap_node("assembler", self._assembler_node))
        workflow.add_node("summary_generator", self.pipeline.wrap_node("summary_generator", self._summary_generator_node))
        
        # å®šä¹‰è¾¹
        workflow.add_edge(START, "researcher")
        workflow.add_edge("researcher", "planner")
        workflow.add_edge("planner", "writer")
        
        # Writer åè¿›å…¥çŸ¥è¯†ç©ºç™½æ£€æŸ¥
        workflow.add_edge("writer", "check_knowledge")
        
        # æ¡ä»¶è¾¹ï¼šæ£€æŸ¥åå†³å®šæ˜¯æœç´¢è¿˜æ˜¯ç»§ç»­åˆ° Questioner
        workflow.add_conditional_edges(
            "check_knowledge",
            self._should_refine_search,
            {
                "search": "refine_search",
                "continue": "questioner"
            }
        )
        
        # æœç´¢åå¢å¼ºå†…å®¹ï¼Œç„¶åå›åˆ°çŸ¥è¯†æ£€æŸ¥
        workflow.add_edge("refine_search", "enhance_with_knowledge")
        workflow.add_edge("enhance_with_knowledge", "check_knowledge")
        
        # æ¡ä»¶è¾¹ï¼šè¿½é—®åå†³å®šæ˜¯æ·±åŒ–è¿˜æ˜¯ç»§ç»­
        workflow.add_conditional_edges(
            "questioner",
            self._should_deepen,
            {
                "deepen": "deepen_content",
                "continue": "section_evaluate"  # è¿›å…¥æ®µè½è¯„ä¼°
            }
        )
        workflow.add_edge("deepen_content", "questioner")  # æ·±åŒ–åé‡æ–°è¿½é—®

        # æ®µè½è¯„ä¼° â†’ æ¡ä»¶è¾¹ï¼šéœ€è¦æ”¹è¿›åˆ™è¿›å…¥æ”¹è¿›èŠ‚ç‚¹ï¼Œå¦åˆ™è·³è¿‡
        workflow.add_conditional_edges(
            "section_evaluate",
            self._should_improve_sections,
            {
                "improve": "section_improve",
                "continue": "coder_and_artist",
            }
        )
        workflow.add_edge("section_improve", "section_evaluate")  # æ”¹è¿›åé‡æ–°è¯„ä¼°
        
        # Coder å’Œ Artist å¹¶è¡Œæ‰§è¡Œï¼ˆé€šè¿‡å•ä¸ªèŠ‚ç‚¹å†…éƒ¨å¹¶è¡Œå®ç°ï¼‰
        workflow.add_edge("coder_and_artist", "cross_section_dedup")
        workflow.add_edge("cross_section_dedup", "consistency_check")
        workflow.add_edge("consistency_check", "reviewer")
        
        # æ¡ä»¶è¾¹ï¼šå®¡æ ¸åå†³å®šæ˜¯ä¿®è®¢è¿˜æ˜¯è¿›å…¥å» AI å‘³
        workflow.add_conditional_edges(
            "reviewer",
            self._should_revise,
            {
                "revision": "revision",
                "assemble": "factcheck"
            }
        )
        workflow.add_edge("revision", "reviewer")  # ä¿®è®¢åé‡æ–°å®¡æ ¸
        workflow.add_edge("factcheck", "text_cleanup")  # äº‹å®æ ¸æŸ¥åæ–‡æœ¬æ¸…ç†
        workflow.add_edge("text_cleanup", "humanizer")  # æ–‡æœ¬æ¸…ç†åå» AI å‘³
        workflow.add_edge("humanizer", "assembler")  # å» AI å‘³åç»„è£…
        workflow.add_edge("assembler", "summary_generator")
        workflow.add_edge("summary_generator", END)
        
        return workflow
    
    def _researcher_node(self, state: SharedState) -> SharedState:
        """ç´ ææ”¶é›†èŠ‚ç‚¹"""
        if state.get('skip_researcher'):
            logger.info("=== Step 1: ç´ ææ”¶é›†ï¼ˆå·²è·³è¿‡ï¼‰ ===")
            return state
        logger.info("=== Step 1: ç´ ææ”¶é›† ===")
        self._validate_layer("research", state)
        return self.researcher.run(state)
    
    def _planner_node(self, state: SharedState) -> SharedState:
        """å¤§çº²è§„åˆ’èŠ‚ç‚¹"""
        logger.info("=== Step 2: å¤§çº²è§„åˆ’ ===")
        self._validate_layer("structure", state)
        # ä½¿ç”¨å®ä¾‹å˜é‡ä¸­çš„æµå¼å›è°ƒ
        on_stream = getattr(self, '_outline_stream_callback', None)
        result = self.planner.run(state, on_stream=on_stream)

        # äº¤äº’å¼æ¨¡å¼ï¼šä½¿ç”¨ LangGraph åŸç”Ÿ interrupt æš‚åœå›¾æ‰§è¡Œ
        outline = result.get('outline') if isinstance(result, dict) else None
        if outline and getattr(self, '_interactive', False):
            sections = outline.get('sections', [])
            interrupt_data = {
                "type": "confirm_outline",
                "title": outline.get("title", ""),
                "sections": sections,
                "sections_titles": [s.get("title", "") for s in sections],
                "narrative_mode": outline.get("narrative_mode", ""),
                "narrative_flow": outline.get("narrative_flow", {}),
                "sections_narrative_roles": [s.get("narrative_role", "") for s in sections],
            }
            user_decision = interrupt(interrupt_data)

            # å¤„ç†ç”¨æˆ·å†³ç­–
            if isinstance(user_decision, dict) and user_decision.get("action") == "edit":
                edited_outline = user_decision.get("outline", outline)
                logger.info(f"å¤§çº²å·²è¢«ç”¨æˆ·ä¿®æ”¹: {edited_outline.get('title', '')}")
                result['outline'] = edited_outline
                result['sections'] = []  # æ¸…ç©ºå·²æœ‰ç« èŠ‚ï¼Œé‡æ–°å†™ä½œ
            else:
                logger.info("å¤§çº²å·²è¢«ç”¨æˆ·ç¡®è®¤")

        # 102.06: åŒ¹é…å†™ä½œæŠ€èƒ½ï¼Œæ³¨å…¥åˆ° state ä¾› writer ä½¿ç”¨
        if self._writing_skill_manager:
            try:
                topic = state.get('topic', '')
                article_type = state.get('article_type', '')
                skill = self._writing_skill_manager.match_skill(topic, article_type)
                if skill:
                    result['_writing_skill_prompt'] = self._writing_skill_manager.build_system_prompt_section(skill)
                    logger.info(f"åŒ¹é…å†™ä½œæŠ€èƒ½: {skill.name}")
            except Exception as e:
                logger.debug(f"å†™ä½œæŠ€èƒ½åŒ¹é…è·³è¿‡: {e}")

        # 41.05 å›¾ç‰‡é¢„è§„åˆ’ï¼šåœ¨å¤§çº²ç¡®è®¤åã€å†™ä½œå‰ç”Ÿæˆå…¨å±€å›¾ç‰‡è®¡åˆ’
        if os.environ.get('IMAGE_PREPLAN_ENABLED', 'false').lower() == 'true':
            try:
                from .image_preplanner import ImagePreplanner
                preplanner = ImagePreplanner(self.llm)
                outline = result.get('outline', {})
                image_plan = preplanner.plan(
                    outline=outline,
                    background_knowledge=state.get('background_knowledge', ''),
                    article_type=state.get('article_type', 'tutorial'),
                )
                result['image_preplan'] = image_plan
                logger.info(f"[41.05] å›¾ç‰‡é¢„è§„åˆ’å®Œæˆ: {len(image_plan)} å¼ ")
            except Exception as e:
                logger.warning(f"[41.05] å›¾ç‰‡é¢„è§„åˆ’å¤±è´¥: {e}")

        return result
    
    def _writer_node(self, state: SharedState) -> SharedState:
        """å†…å®¹æ’°å†™èŠ‚ç‚¹"""
        logger.info("=== Step 3: å†…å®¹æ’°å†™ ===")
        self._validate_layer("content", state)

        # 102.03: æ³¨å…¥ç”¨æˆ·è®°å¿†åˆ° background_knowledge
        if self._memory_storage:
            try:
                user_id = state.get('user_id', 'default')
                memory_injection = self._memory_storage.format_for_injection(user_id)
                if memory_injection:
                    bg = state.get('background_knowledge', '')
                    state['background_knowledge'] = bg + "\n\n" + memory_injection if bg else memory_injection
                    logger.info(f"æ³¨å…¥ç”¨æˆ·è®°å¿†: {len(memory_injection)} å­—ç¬¦")
            except Exception as e:
                logger.debug(f"ç”¨æˆ·è®°å¿†æ³¨å…¥è·³è¿‡: {e}")

        # 41.10: æ³¨å…¥äººè®¾ Prompt åˆ° stateï¼ˆä¾› Writer ä½¿ç”¨ï¼‰
        style = self._get_style(state)
        persona_prompt = style.get_persona_prompt()
        if persona_prompt:
            state['_persona_prompt'] = persona_prompt
            logger.info(f"[41.10] æ³¨å…¥äººè®¾ Prompt: {persona_prompt[:60]}...")

        before_count = _get_content_word_count(state)
        result = self.writer.run(state)
        after_count = _get_content_word_count(result)
        _log_word_count_diff("Writer", before_count, after_count)
        # åˆå§‹åŒ–ç´¯ç§¯çŸ¥è¯†ï¼ˆé¦–æ¬¡å†™ä½œåï¼‰
        if not result.get('accumulated_knowledge'):
            result['accumulated_knowledge'] = result.get('background_knowledge', '')
        return result
    
    def _check_knowledge_node(self, state: SharedState) -> SharedState:
        """çŸ¥è¯†ç©ºç™½æ£€æŸ¥èŠ‚ç‚¹"""
        search_count = state.get('search_count', 0)
        max_count = state.get('max_search_count', 5)
        logger.info(f"=== Step 3.5: çŸ¥è¯†ç©ºç™½æ£€æŸ¥ (æœç´¢æ¬¡æ•°: {search_count}/{max_count}) ===")
        return self.search_coordinator.run(state)
    
    def _refine_search_node(self, state: SharedState) -> SharedState:
        """ç»†åŒ–æœç´¢èŠ‚ç‚¹"""
        search_count = state.get('search_count', 0) + 1
        max_count = state.get('max_search_count', 5)
        logger.info(f"=== Step 3.6: ç»†åŒ–æœç´¢ (ç¬¬ {search_count} è½®) ===")
        
        gaps = state.get('knowledge_gaps', [])
        result = self.search_coordinator.refine_search(gaps, state)
        
        if result.get('success'):
            logger.info(f"ç»†åŒ–æœç´¢å®Œæˆ: è·å– {len(result.get('results', []))} æ¡ç»“æœ")
        else:
            logger.warning(f"ç»†åŒ–æœç´¢å¤±è´¥: {result.get('reason', 'æœªçŸ¥åŸå› ')}")
        
        return state
    
    def _enhance_with_knowledge_node(self, state: SharedState) -> SharedState:
        """åŸºäºæ–°çŸ¥è¯†å¢å¼ºå†…å®¹èŠ‚ç‚¹ï¼ˆ102.01 è¿ç§»ï¼šä½¿ç”¨ ParallelTaskExecutorï¼‰"""
        logger.info("=== Step 3.7: çŸ¥è¯†å¢å¼º ===")

        sections = state.get('sections', [])
        gaps = state.get('knowledge_gaps', [])
        new_knowledge = state.get('accumulated_knowledge', '')

        if not gaps or not new_knowledge:
            logger.info("æ²¡æœ‰éœ€è¦å¢å¼ºçš„å†…å®¹")
            return state

        from .prompts import get_prompt_manager
        pm = get_prompt_manager()

        # æ”¶é›†éœ€è¦å¢å¼ºçš„ä»»åŠ¡
        enhance_items = []
        for section in sections:
            section_gaps = [g for g in gaps if not g.get('section_id') or g.get('section_id') == section.get('id')]
            if section_gaps:
                enhance_items.append((section, section_gaps))

        if not enhance_items:
            logger.info("æ²¡æœ‰éœ€è¦å¢å¼ºçš„ç« èŠ‚")
            state['knowledge_gaps'] = []
            return state

        def enhance_single(section, section_gaps):
            prompt = pm.render_writer_enhance_with_knowledge(
                original_content=section.get('content', ''),
                new_knowledge=new_knowledge,
                knowledge_gaps=section_gaps,
            )
            return self.writer.llm.chat(messages=[{"role": "user", "content": prompt}])

        tasks = [
            {
                "name": f"å¢å¼º-{section.get('title', '')}",
                "fn": enhance_single,
                "args": (section, section_gaps),
            }
            for section, section_gaps in enhance_items
        ]

        results = self.executor.run_parallel(tasks, config=TaskConfig(
            name="knowledge_enhance", timeout_seconds=120,
        ))

        for i, r in enumerate(results):
            if r.success:
                enhance_items[i][0]['content'] = r.result
                logger.info(f"ç« èŠ‚å¢å¼ºå®Œæˆ: {enhance_items[i][0].get('title', '')}")
            else:
                logger.error(f"ç« èŠ‚å¢å¼ºå¤±è´¥: {r.error}")

        enhanced_count = sum(1 for r in results if r.success)
        logger.info(f"çŸ¥è¯†å¢å¼ºå®Œæˆ: {enhanced_count} ä¸ªç« èŠ‚")
        state['knowledge_gaps'] = []
        return state
    
    
    
    def _questioner_node(self, state: SharedState) -> SharedState:
        """è¿½é—®æ£€æŸ¥èŠ‚ç‚¹"""
        logger.info("=== Step 4: è¿½é—®æ£€æŸ¥ ===")
        return self.questioner.run(state)
    
    def _deepen_content_node(self, state: SharedState) -> SharedState:
        """å†…å®¹æ·±åŒ–èŠ‚ç‚¹ï¼ˆ102.01 è¿ç§»ï¼šä½¿ç”¨ ParallelTaskExecutorï¼‰"""
        logger.info("=== Step 4.1: å†…å®¹æ·±åŒ– ===")
        before_count = _get_content_word_count(state)
        state['questioning_count'] = state.get('questioning_count', 0) + 1

        sections_to_deepen = [
            r for r in state.get('question_results', [])
            if not r.get('is_detailed_enough', True)
        ]
        total_to_deepen = len(sections_to_deepen)

        if total_to_deepen == 0:
            logger.info("æ²¡æœ‰éœ€è¦æ·±åŒ–çš„ç« èŠ‚")
            return state

        # æ„å»ºä»»åŠ¡åˆ—è¡¨
        tasks = []
        for idx, result in enumerate(sections_to_deepen, 1):
            section_id = result.get('section_id', '')
            vague_points = result.get('vague_points', [])

            for section in state.get('sections', []):
                if section.get('id') == section_id:
                    section_title = section.get('title', section_id)
                    progress_info = f"[{idx}/{total_to_deepen}]"
                    tasks.append({
                        "name": f"æ·±åŒ–-{section_title}",
                        "fn": self.writer.enhance_section,
                        "kwargs": {
                            "original_content": section.get('content', ''),
                            "vague_points": vague_points,
                            "section_title": section_title,
                            "progress_info": progress_info,
                        },
                        "_section_id": section_id,
                    })
                    break

        results = self.executor.run_parallel(tasks, config=TaskConfig(
            name="content_deepen", timeout_seconds=120,
        ))

        # å›å†™ç»“æœ
        for i, r in enumerate(results):
            if r.success:
                target_id = tasks[i]["_section_id"]
                for section in state.get('sections', []):
                    if section.get('id') == target_id:
                        section['content'] = r.result
                        logger.info(f"ç« èŠ‚æ·±åŒ–å®Œæˆ: {section.get('title', '')}")
                        break
            else:
                logger.error(f"ç« èŠ‚æ·±åŒ–å¤±è´¥: {r.error}")

        after_count = _get_content_word_count(state)
        _log_word_count_diff("å†…å®¹æ·±åŒ–", before_count, after_count)

        # 69.05: è®°å½•æ·±åŒ–è¿­ä»£å¿«ç…§
        self.tracker.log_deepen_snapshot(
            round_num=state.get('questioning_count', 0),
            sections_deepened=total_to_deepen,
            chars_added=after_count - before_count,
        )

        return state

    # ========== æ®µè½çº§ Generator-Critic Loop (#69.04) ==========

    def _section_evaluate_node(self, state: SharedState) -> SharedState:
        """æ®µè½å¤šç»´åº¦è¯„ä¼°èŠ‚ç‚¹ï¼ˆCritic è§’è‰²ï¼‰"""
        # åŒå¼€å…³ï¼šç¯å¢ƒå˜é‡ + StyleProfile
        style = self._get_style(state)
        if not self._is_enabled("SECTION_EVAL_ENABLED", getattr(style, "enable_thread_check", True)):
            logger.info("æ®µè½è¯„ä¼°å·²ç¦ç”¨ï¼Œè·³è¿‡")
            state["section_evaluations"] = []
            state["needs_section_improvement"] = False
            return state

        logger.info("=== Step 4.2: æ®µè½å¤šç»´åº¦è¯„ä¼° ===")
        sections = state.get("sections", [])
        evaluations = []
        needs_improvement = False

        for i, section in enumerate(sections):
            prev_summary = sections[i - 1].get("title", "") if i > 0 else ""
            next_preview = sections[i + 1].get("title", "") if i < len(sections) - 1 else ""

            evaluation = self.questioner.evaluate_section(
                section_content=section.get("content", ""),
                section_title=section.get("title", ""),
                prev_summary=prev_summary,
                next_preview=next_preview,
            )
            evaluation["section_idx"] = i
            evaluations.append(evaluation)

            if evaluation["overall_quality"] < 7.0:
                needs_improvement = True
                logger.info(
                    f"  æ®µè½ [{section.get('title', '')}] éœ€æ”¹è¿›: "
                    f"overall={evaluation['overall_quality']}"
                )

        state["section_evaluations"] = evaluations
        state["needs_section_improvement"] = needs_improvement

        avg_score = (
            sum(e["overall_quality"] for e in evaluations) / max(len(evaluations), 1)
        )
        logger.info(f"æ®µè½è¯„ä¼°å®Œæˆ: å¹³å‡åˆ† {avg_score:.1f}, éœ€æ”¹è¿›={needs_improvement}")

        # 69.05: è®°å½•æ®µè½è¯„ä¼°åˆ†æ•°
        for evaluation in evaluations:
            self.tracker.log_section_evaluation(
                section_title=sections[evaluation.get("section_idx", 0)].get("title", ""),
                scores=evaluation.get("scores", {}),
                overall=evaluation["overall_quality"],
            )

        return state

    def _should_improve_sections(self, state: SharedState) -> str:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æ®µè½çº§æ”¹è¿›"""
        if not state.get("needs_section_improvement", False):
            return "continue"

        improve_count = state.get("section_improve_count", 0)
        if improve_count >= 2:
            logger.info("æ®µè½æ”¹è¿›è¾¾åˆ°æœ€å¤§è½®æ•°(2)ï¼Œè·³è¿‡")
            return "continue"

        # æ”¶æ•›æ£€æµ‹ï¼šæ”¹è¿›å¹…åº¦ < 0.3 åˆ™åœæ­¢
        evaluations = state.get("section_evaluations", [])
        curr_avg = (
            sum(e["overall_quality"] for e in evaluations) / max(len(evaluations), 1)
        )
        prev_avg = state.get("prev_section_avg_score", 0)
        if prev_avg > 0 and (curr_avg - prev_avg) < 0.3:
            logger.info(f"æ®µè½æ”¹è¿›æ”¶æ•› ({prev_avg:.1f} â†’ {curr_avg:.1f})ï¼Œè·³è¿‡")
            return "continue"

        state["prev_section_avg_score"] = curr_avg
        return "improve"

    def _section_improve_node(self, state: SharedState) -> SharedState:
        """æ®µè½ç²¾å‡†æ”¹è¿›èŠ‚ç‚¹ï¼ˆGenerator è§’è‰²ï¼‰"""
        logger.info("=== Step 4.3: æ®µè½ç²¾å‡†æ”¹è¿› ===")
        evaluations = state.get("section_evaluations", [])
        sections = state.get("sections", [])
        improved_count = 0

        for evaluation in evaluations:
            idx = evaluation.get("section_idx", -1)
            if evaluation["overall_quality"] >= 7.0 or idx < 0 or idx >= len(sections):
                continue

            section = sections[idx]
            improved_content = self.writer.improve_section(
                original_content=section.get("content", ""),
                critique=evaluation,
                section_title=section.get("title", ""),
            )
            section["content"] = improved_content
            improved_count += 1

        state["section_improve_count"] = state.get("section_improve_count", 0) + 1
        logger.info(f"æ®µè½æ”¹è¿›å®Œæˆ: æ”¹è¿›äº† {improved_count} ä¸ªæ®µè½ (ç¬¬ {state['section_improve_count']} è½®)")

        # 69.05: è®°å½•æ®µè½æ”¹è¿›å¿«ç…§
        new_avg = (
            sum(e["overall_quality"] for e in evaluations) / max(len(evaluations), 1)
        )
        self.tracker.log_section_improve_snapshot(
            round_num=state["section_improve_count"],
            improved_count=improved_count,
            avg_score_before=state.get("prev_section_avg_score", 0),
            avg_score_after=new_avg,
        )

        return state
    
    def _coder_and_artist_node(self, state: SharedState) -> SharedState:
        """ä»£ç å’Œé…å›¾å¹¶è¡Œç”ŸæˆèŠ‚ç‚¹ï¼ˆ102.01 è¿ç§»ï¼šä½¿ç”¨ ParallelTaskExecutorï¼‰"""
        logger.info("=== Step 5: ä»£ç å’Œé…å›¾å¹¶è¡Œç”Ÿæˆ ===")

        tasks = [
            {"name": "ä»£ç ç”Ÿæˆ", "fn": self.coder.run, "args": (state,)},
            {"name": "é…å›¾ç”Ÿæˆ", "fn": self.artist.run, "args": (state,)},
        ]
        results = self.executor.run_parallel(tasks, config=TaskConfig(
            name="coder_and_artist", timeout_seconds=180,
        ))

        # åˆå¹¶ç»“æœ
        for r in results:
            if r.success and isinstance(r.result, dict):
                if 'section_images' in r.result:
                    state['section_images'] = r.result['section_images']
                    logger.info(f"åˆå¹¶ section_images: {len(state['section_images'])} å¼ ")
                if 'images' in r.result:
                    state['images'] = r.result['images']

        code_count = len(state.get('code_blocks', []))
        image_count = len(state.get('images', []))
        logger.info(f"=== ä»£ç å’Œé…å›¾å¹¶è¡Œç”Ÿæˆå®Œæˆ: {code_count} ä¸ªä»£ç å—, {image_count} å¼ å›¾ç‰‡ ===")

        # 69.05: è®°å½•é…å›¾ç”Ÿæˆç»“æœ
        for img in state.get('images', []):
            self.tracker.log_image_generation(
                image_id=img.get('id', ''),
                image_type=img.get('render_method', ''),
                success=True,
            )

        return state
    
    def _reviewer_node(self, state: SharedState) -> SharedState:
        """è´¨é‡å®¡æ ¸èŠ‚ç‚¹"""
        logger.info("=== Step 7: è´¨é‡å®¡æ ¸ ===")
        state = self.reviewer.run(state)

        # åˆå¹¶ä¸€è‡´æ€§æ£€æŸ¥å‘ç°çš„é—®é¢˜åˆ° review_issues
        consistency_issues = state.get('thread_issues', []) + state.get('voice_issues', [])
        if consistency_issues:
            existing = state.get('review_issues', [])
            state['review_issues'] = existing + consistency_issues
            logger.info(f"[Reviewer] åˆå¹¶ä¸€è‡´æ€§æ£€æŸ¥é—®é¢˜: {len(consistency_issues)} æ¡")

        # 69.05: è®°å½•å®¡æ ¸åˆ†æ•°åˆ° Langfuse
        self.tracker.log_review_score(
            score=state.get('review_score', 0),
            round_num=state.get('revision_count', 0),
            summary=f"issues={len(state.get('review_issues', []))} approved={state.get('review_approved', False)}",
        )

        return state
    
    def _revision_node(self, state: SharedState) -> SharedState:
        """ä¿®è®¢èŠ‚ç‚¹ï¼ˆ102.01 è¿ç§»ï¼šä½¿ç”¨ ParallelTaskExecutorï¼‰"""
        logger.info("=== Step 7.1: ä¿®è®¢ ===")
        before_count = _get_content_word_count(state)
        state['revision_count'] = state.get('revision_count', 0) + 1

        review_issues = state.get('review_issues', [])
        total_issues = len(review_issues)
        style = self._get_style(state)

        if total_issues == 0:
            logger.info("æ²¡æœ‰éœ€è¦ä¿®è®¢çš„é—®é¢˜")
            return state

        if style.revision_strategy == "correct_only":
            self._revision_correct_only(state, review_issues)
        else:
            self._revision_enhance(state, review_issues)

        after_count = _get_content_word_count(state)
        _log_word_count_diff("ä¿®è®¢", before_count, after_count)
        return state

    def _revision_correct_only(self, state, review_issues):
        """correct_only æ¨¡å¼ï¼šæŒ‰ç« èŠ‚åˆ†ç»„ï¼Œä½¿ç”¨ correct_section"""
        section_issues = {}
        for issue in review_issues:
            section_id = issue.get('section_id', '')
            if section_id not in section_issues:
                section_issues[section_id] = []
            section_issues[section_id].append({
                'severity': issue.get('severity', 'medium'),
                'description': issue.get('description', ''),
                'affected_content': issue.get('affected_content', ''),
            })

        tasks = []
        for idx, (section_id, issues) in enumerate(section_issues.items(), 1):
            for section in state.get('sections', []):
                if section.get('id') == section_id:
                    section_title = section.get('title', section_id)
                    progress_info = f"[{idx}/{len(section_issues)}]"
                    tasks.append({
                        "name": f"æ›´æ­£-{section_title}",
                        "fn": self.writer.correct_section,
                        "kwargs": {
                            "original_content": section.get('content', ''),
                            "issues": issues,
                            "section_title": section_title,
                            "progress_info": progress_info,
                        },
                        "_section_id": section_id,
                    })
                    break

        results = self.executor.run_parallel(tasks, config=TaskConfig(
            name="revision_correct", timeout_seconds=120,
        ))

        for i, r in enumerate(results):
            if r.success:
                target_id = tasks[i]["_section_id"]
                for section in state.get('sections', []):
                    if section.get('id') == target_id:
                        section['content'] = r.result
                        break
            else:
                logger.error(f"ç« èŠ‚æ›´æ­£å¤±è´¥: {r.error}")

    def _revision_enhance(self, state, review_issues):
        """enhance æ¨¡å¼ï¼šæŒ‰é—®é¢˜é€ä¸ªä¿®è®¢"""
        tasks = []
        for idx, issue in enumerate(review_issues, 1):
            section_id = issue.get('section_id', '')
            suggestion = issue.get('suggestion', '')

            for section in state.get('sections', []):
                if section.get('id') == section_id:
                    section_title = section.get('title', section_id)
                    progress_info = f"[{idx}/{len(review_issues)}]"
                    tasks.append({
                        "name": f"ä¿®è®¢-{section_title}",
                        "fn": self.writer.enhance_section,
                        "kwargs": {
                            "original_content": section.get('content', ''),
                            "vague_points": [{
                                'location': section_title,
                                'issue': issue.get('description', ''),
                                'question': suggestion,
                                'suggestion': 'æ ¹æ®å®¡æ ¸å»ºè®®ä¿®æ”¹',
                            }],
                            "section_title": section_title,
                            "progress_info": progress_info,
                        },
                        "_section_id": section_id,
                    })
                    break

        results = self.executor.run_parallel(tasks, config=TaskConfig(
            name="revision_enhance", timeout_seconds=120,
        ))

        for i, r in enumerate(results):
            if r.success:
                target_id = tasks[i]["_section_id"]
                for section in state.get('sections', []):
                    if section.get('id') == target_id:
                        section['content'] = r.result
                        break
            else:
                logger.error(f"ç« èŠ‚ä¿®è®¢å¤±è´¥: {r.error}")

    def _cross_section_dedup_node(self, state: SharedState) -> SharedState:
        """41.09 è·¨ç« èŠ‚è¯­ä¹‰å»é‡èŠ‚ç‚¹"""
        if os.environ.get('CROSS_SECTION_DEDUP_ENABLED', 'false').lower() != 'true':
            return state
        sections = state.get('sections', [])
        if len(sections) < 2:
            return state
        logger.info("=== Step 5.5: è·¨ç« èŠ‚è¯­ä¹‰å»é‡ ===")
        try:
            from .cross_section_dedup import CrossSectionDeduplicator
            dedup = CrossSectionDeduplicator(llm_client=self.llm)
            state['sections'] = dedup.deduplicate(sections)
        except Exception as e:
            logger.warning(f"[Dedup] å¼‚å¸¸ï¼Œè·³è¿‡å»é‡: {e}")
        return state

    def _consistency_check_node(self, state: SharedState) -> SharedState:
        """ä¸€è‡´æ€§æ£€æŸ¥èŠ‚ç‚¹ï¼ˆ102.01 è¿ç§»ï¼šä½¿ç”¨ ParallelTaskExecutorï¼‰"""
        sections = state.get('sections', [])
        if len(sections) < 2:
            state['thread_issues'] = []
            state['voice_issues'] = []
            return state

        style = self._get_style(state)
        thread_enabled = self._is_enabled(self._env_thread_check, style.enable_thread_check)
        voice_enabled = self._is_enabled(self._env_voice_check, style.enable_voice_check)

        if not thread_enabled and not voice_enabled:
            state['thread_issues'] = []
            state['voice_issues'] = []
            return state

        logger.info("=== Step 6.5: ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆå™äº‹ + è¯­æ°”ï¼‰===")

        tasks = []
        if thread_enabled:
            tasks.append({"name": "å™äº‹ä¸€è‡´æ€§", "fn": self.thread_checker.run, "args": (state,)})
        if voice_enabled:
            tasks.append({"name": "è¯­æ°”ä¸€è‡´æ€§", "fn": self.voice_checker.run, "args": (state,)})

        results = self.executor.run_parallel(tasks, config=TaskConfig(
            name="consistency_check", timeout_seconds=120,
        ))

        for r in results:
            if not r.success:
                logger.error(f"[ConsistencyCheck] {r.task_name} å¼‚å¸¸: {r.error}")

        if not thread_enabled:
            state['thread_issues'] = []
        if not voice_enabled:
            state['voice_issues'] = []

        thread_count = len(state.get('thread_issues', []))
        voice_count = len(state.get('voice_issues', []))
        logger.info(f"[ConsistencyCheck] å®Œæˆ: å™äº‹é—®é¢˜ {thread_count}, è¯­æ°”é—®é¢˜ {voice_count}")
        return state

    def _get_style(self, state: SharedState) -> StyleProfile:
        """è·å–å½“å‰è¿è¡Œçš„ StyleProfileï¼ˆå®ä¾‹çº§ > state çº§ > target_length æ¨æ–­ï¼‰"""
        if self.style:
            return self.style
        target_length = state.get('target_length', 'medium')
        return StyleProfile.from_target_length(target_length)

    def _is_enabled(self, env_flag: bool, style_flag: bool) -> bool:
        """ç¯å¢ƒå˜é‡ AND StyleProfile åŒé‡å¼€å…³"""
        return env_flag and style_flag

    def _factcheck_node(self, state: SharedState) -> SharedState:
        """äº‹å®æ ¸æŸ¥èŠ‚ç‚¹"""
        style = self._get_style(state)
        if not self._is_enabled(self._env_factcheck, style.enable_fact_check):
            logger.info("=== Step 7.3: äº‹å®æ ¸æŸ¥ï¼ˆå·²ç¦ç”¨ï¼Œè·³è¿‡ï¼‰===")
            return state
        logger.info("=== Step 7.3: äº‹å®æ ¸æŸ¥ ===")
        try:
            return self.factcheck.run(state)
        except Exception as e:
            logger.error(f"[FactCheck] å¼‚å¸¸ï¼Œé™çº§è·³è¿‡: {e}")
            return state

    def _text_cleanup_node(self, state: SharedState) -> SharedState:
        """ç¡®å®šæ€§æ–‡æœ¬æ¸…ç†èŠ‚ç‚¹ï¼ˆçº¯æ­£åˆ™ï¼Œé›¶ LLMï¼‰"""
        style = self._get_style(state)
        if not self._is_enabled(self._env_text_cleanup, style.enable_text_cleanup):
            logger.info("=== Step 7.4: æ–‡æœ¬æ¸…ç†ï¼ˆå·²ç¦ç”¨ï¼Œè·³è¿‡ï¼‰===")
            return state
        logger.info("=== Step 7.4: ç¡®å®šæ€§æ–‡æœ¬æ¸…ç† ===")
        from utils.text_cleanup import apply_full_cleanup
        total_fixes = 0
        for section in state.get('sections', []):
            content = section.get('content', '')
            if not content:
                continue
            result = apply_full_cleanup(content)
            section['content'] = result['text']
            fixes = result['total_fixes']
            if fixes:
                logger.info(f"  [{section.get('title', '')}] ä¿®å¤ {fixes} å¤„: {result['stats']}")
                total_fixes += fixes
        logger.info(f"[TextCleanup] å®Œæˆ: å…±ä¿®å¤ {total_fixes} å¤„")
        return state

    def _humanizer_node(self, state: SharedState) -> SharedState:
        """å» AI å‘³èŠ‚ç‚¹"""
        style = self._get_style(state)
        if not self._is_enabled(self._env_humanizer, style.enable_humanizer):
            logger.info("=== Step 7.5: å» AI å‘³ï¼ˆå·²ç¦ç”¨ï¼Œè·³è¿‡ï¼‰===")
            return state
        logger.info("=== Step 7.5: å» AI å‘³ ===")
        try:
            return self.humanizer.run(state)
        except Exception as e:
            logger.error(f"[Humanizer] å¼‚å¸¸ï¼Œé™çº§ä½¿ç”¨åŸå§‹å†…å®¹: {e}")
            return state

    def _summary_generator_node(self, state: SharedState) -> SharedState:
        """åšå®¢å¯¼è¯» + SEO å…³é”®è¯ç”ŸæˆèŠ‚ç‚¹"""
        style = self._get_style(state)
        if not self._is_enabled(self._env_summary, style.enable_summary_gen):
            logger.info("=== Step 9: å¯¼è¯»+SEOï¼ˆå·²ç¦ç”¨ï¼Œè·³è¿‡ï¼‰===")
            return state
        logger.info("=== Step 9: å¯¼è¯» + SEO å…³é”®è¯ç”Ÿæˆ ===")
        try:
            return self.summary_generator.run(state)
        except Exception as e:
            logger.error(f"[SummaryGenerator] å¼‚å¸¸ï¼Œé™çº§è·³è¿‡: {e}")
            return state

    def _assembler_node(self, state: SharedState) -> SharedState:
        """æ–‡æ¡£ç»„è£…èŠ‚ç‚¹"""
        logger.info("=== Step 8: æ–‡æ¡£ç»„è£… ===")
        return self.assembler.run(state)
    
    def _should_deepen(self, state: SharedState) -> Literal["deepen", "continue"]:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æ·±åŒ–å†…å®¹"""
        MAX_DEEPEN_ROUNDS = 5  # ç¡¬é™åˆ¶ï¼Œé˜²æ­¢æ— é™å¾ªç¯
        if state.get('questioning_count', 0) >= MAX_DEEPEN_ROUNDS:
            logger.warning(f"æ·±åŒ–è½®æ•°è¾¾åˆ°ç¡¬é™åˆ¶ ({MAX_DEEPEN_ROUNDS})ï¼Œå¼ºåˆ¶è·³è¿‡")
            return "continue"
        if not state.get('all_sections_detailed', True):
            if state.get('questioning_count', 0) < self.max_questioning_rounds:
                return "deepen"
        return "continue"
    
    def _should_revise(self, state: SharedState) -> Literal["revision", "assemble"]:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ä¿®è®¢ â€” ç”± StyleProfile æ§åˆ¶"""
        style = self._get_style(state)
        revision_count = state.get('revision_count', 0)

        # è¾¾åˆ°æœ€å¤§ä¿®è®¢è½®æ•°
        if revision_count >= style.max_revision_rounds:
            logger.info(f"å·²è¾¾åˆ°æœ€å¤§ä¿®è®¢è½®æ•° ({style.max_revision_rounds})ï¼Œè·³è¿‡ä¿®è®¢")
            return "assemble"

        review_issues = state.get('review_issues', [])

        # ä¿®è®¢é—®é¢˜è¿‡æ»¤ï¼ˆhigh_only æ¨¡å¼ï¼‰
        if style.revision_severity_filter == "high_only":
            high_issues = [i for i in review_issues if i.get('severity') == 'high']
            if high_issues:
                logger.info(f"[{style.revision_severity_filter}] åªå¤„ç† {len(high_issues)} ä¸ª high çº§åˆ«é—®é¢˜")
                state['review_issues'] = high_issues
                return "revision"
            logger.info(f"[{style.revision_severity_filter}] æ—  high çº§åˆ«é—®é¢˜ï¼Œè·³è¿‡ä¿®è®¢")
            return "assemble"

        # å®Œæ•´ä¿®è®¢æ¨¡å¼
        if not state.get('review_approved', True):
            return "revision"

        logger.info("å®¡æ ¸é€šè¿‡æˆ–ä¿®è®¢å®Œæˆï¼Œè¿›å…¥ç»„è£…")
        return "assemble"

    def _should_refine_search(self, state: SharedState) -> Literal["search", "continue"]:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ç»†åŒ–æœç´¢ â€” ç”± StyleProfile æ§åˆ¶"""
        style = self._get_style(state)
        if not style.enable_knowledge_refinement:
            logger.info("çŸ¥è¯†å¢å¼ºå·²ç¦ç”¨ï¼Œè·³è¿‡")
            return "continue"

        gaps = state.get('knowledge_gaps', [])
        search_count = state.get('search_count', 0)
        max_count = state.get('max_search_count', 5)

        if gaps and search_count < max_count:
            important_gaps = [g for g in gaps if g.get('gap_type') in ['missing_data', 'vague_concept']]
            if important_gaps:
                logger.info(f"æ£€æµ‹åˆ° {len(important_gaps)} ä¸ªé‡è¦çŸ¥è¯†ç©ºç™½ï¼Œè§¦å‘ç»†åŒ–æœç´¢")
                return "search"

        logger.info("æ— éœ€ç»†åŒ–æœç´¢ï¼Œç»§ç»­åˆ°è¿½é—®é˜¶æ®µ")
        return "continue"

    def _run_derivative_skills(self, final_state: Dict[str, Any]) -> Dict[str, Any]:
        """37.14/37.16 è¿è¡Œåšå®¢è¡ç”Ÿç‰© Skillsï¼ˆMindMap/Flashcard/StudyNoteï¼‰"""
        if os.environ.get('SKILL_DERIVATIVES_ENABLED', 'false').lower() != 'true':
            return {}
        try:
            from .skills.executor import SkillExecutor
            from .skills.registry import SkillRegistry
            # ç¡®ä¿ skills å·²æ³¨å†Œï¼ˆå¯¼å…¥è§¦å‘ @register è£…é¥°å™¨ï¼‰
            from .skills import mindmap, flashcard, study_note  # noqa: F401

            executor = SkillExecutor()
            markdown = final_state.get('final_markdown', '')
            if not markdown:
                return {}

            input_data = {"markdown": markdown, "topic": final_state.get('topic', '')}
            results = {}
            for skill_name in SkillRegistry.get_post_process_skills():
                try:
                    result = executor.execute(skill_name, input_data)
                    if result.get('success'):
                        results[skill_name] = result.get('output')
                        logger.info(f"ğŸ¯ è¡ç”Ÿç‰© [{skill_name}] ç”Ÿæˆå®Œæˆ")
                except Exception as e:
                    logger.warning(f"è¡ç”Ÿç‰© [{skill_name}] ç”Ÿæˆå¤±è´¥: {e}")
            return results
        except Exception as e:
            logger.warning(f"è¡ç”Ÿç‰©ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            return {}

    def compile(self, checkpointer=None):
        """
        ç¼–è¯‘å·¥ä½œæµ
        
        Args:
            checkpointer: æ£€æŸ¥ç‚¹å­˜å‚¨ (å¯é€‰)
        """
        if checkpointer is None:
            checkpointer = MemorySaver()
        
        self.app = self.workflow.compile(checkpointer=checkpointer)
        return self.app
    
    def generate(
        self,
        topic: str,
        article_type: str = "tutorial",
        target_audience: str = "intermediate",
        target_length: str = "medium",
        source_material: str = None,
        on_progress: Callable[[str, str], None] = None
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆåšå®¢
        
        Args:
            topic: æŠ€æœ¯ä¸»é¢˜
            article_type: æ–‡ç« ç±»å‹
            target_audience: ç›®æ ‡å—ä¼—
            target_length: ç›®æ ‡é•¿åº¦
            source_material: å‚è€ƒèµ„æ–™
            on_progress: è¿›åº¦å›è°ƒ
            
        Returns:
            ç”Ÿæˆç»“æœ
        """
        if self.app is None:
            self.compile()

        # åˆ›å»º Token è¿½è¸ªå™¨å¹¶æ³¨å…¥ LLMService
        token_tracker = None
        cost_tracker = None
        try:
            import os
            if os.environ.get('TOKEN_TRACKING_ENABLED', 'true').lower() == 'true':
                from utils.token_tracker import TokenTracker
                token_tracker = TokenTracker()
                self.llm.token_tracker = token_tracker
            # 41.08 æˆæœ¬è¿½è¸ªå¢å¼º
            if os.environ.get('COST_TRACKING_ENABLED', 'false').lower() == 'true':
                from utils.cost_tracker import CostTracker
                cost_tracker = CostTracker()
                self.llm._cost_tracker = cost_tracker
        except Exception:
            pass

        # åˆ›å»ºç»“æ„åŒ–ä»»åŠ¡æ—¥å¿—
        task_log = None
        try:
            import os as _os
            if _os.environ.get('BLOG_TASK_LOG_ENABLED', 'true').lower() == 'true':
                from .utils.task_log import BlogTaskLog
                task_log = BlogTaskLog(
                    topic=topic,
                    article_type=article_type,
                    target_length=target_length,
                )
                self.task_log = task_log
                # æ³¨å…¥åˆ°ä¸­é—´ä»¶ï¼Œè‡ªåŠ¨è®°å½•æ¯ä¸ªèŠ‚ç‚¹è€—æ—¶
                self._task_log_middleware.set_task_log(task_log)
        except Exception:
            pass

        # åˆ›å»º ToolManager å¹¶æ³¨å†Œç°æœ‰å·¥å…·ï¼ˆ37.09ï¼‰
        try:
            from utils.tool_manager import BlogToolManager
            tool_manager = BlogToolManager(task_log=task_log)
            if self.search_service:
                tool_manager.register(
                    "web_search", self.search_service.search,
                    description="æœç´¢äº’è”ç½‘è·å–èƒŒæ™¯çŸ¥è¯†", timeout=30,
                )
            self.tool_manager = tool_manager
        except Exception:
            pass

        # åˆ›å»ºåˆå§‹çŠ¶æ€
        initial_state = create_initial_state(
            topic=topic,
            article_type=article_type,
            target_audience=target_audience,
            target_length=target_length,
            source_material=source_material
        )

        # 102.10 è¿ç§»ï¼šè®¾ç½®è¿½è¸ª ID
        initial_state["trace_id"] = str(uuid.uuid4())[:8]
        
        logger.info(f"å¼€å§‹ç”Ÿæˆåšå®¢: {topic}")
        logger.info(f"  ç±»å‹: {article_type}, å—ä¼—: {target_audience}, é•¿åº¦: {target_length}")
        
        # æ‰§è¡Œå·¥ä½œæµ
        config = {"configurable": {"thread_id": f"blog_{topic}"}}
        
        try:
            final_state = self.app.invoke(initial_state, config)
            
            logger.info("åšå®¢ç”Ÿæˆå®Œæˆ!")

            # è¾“å‡º Token ç”¨é‡æ‘˜è¦
            token_summary = None
            if token_tracker:
                logger.info(token_tracker.format_summary())
                token_summary = token_tracker.get_summary()

            # 41.08 æˆæœ¬æ‘˜è¦
            cost_summary = None
            if cost_tracker:
                logger.info(cost_tracker.format_summary())
                cost_summary = cost_tracker.get_summary()

            # å®Œæˆä»»åŠ¡æ—¥å¿—
            if task_log:
                task_log.complete(
                    score=final_state.get('review_score', 0),
                    word_count=len(final_state.get('final_markdown', '')),
                    revision_rounds=final_state.get('revision_count', 0),
                )
                if token_summary:
                    task_log.token_summary = token_summary
                try:
                    task_log.save()
                except Exception as save_err:
                    logger.warning(f"ä»»åŠ¡æ—¥å¿—ä¿å­˜å¤±è´¥: {save_err}")
                logger.info(task_log.get_summary())

            result = {
                "success": True,
                "markdown": final_state.get('final_markdown', ''),
                "outline": final_state.get('outline', {}),
                "sections_count": len(final_state.get('sections', [])),
                "images_count": len(final_state.get('images', [])),
                "code_blocks_count": len(final_state.get('code_blocks', [])),
                "review_score": final_state.get('review_score', 0),
                "seo_keywords": final_state.get('seo_keywords', []),
                "social_summary": final_state.get('social_summary', ''),
                "meta_description": final_state.get('meta_description', ''),
                "error": None
            }
            if token_summary:
                result["token_summary"] = token_summary
            if cost_summary:
                result["cost_summary"] = cost_summary

            # 37.14/37.16 åšå®¢è¡ç”Ÿç‰©ç”Ÿæˆï¼ˆSkill åå¤„ç†ï¼‰
            derivatives = self._run_derivative_skills(final_state)
            if derivatives:
                result["derivatives"] = derivatives

            return result
            
        except Exception as e:
            logger.error(f"åšå®¢ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
            if task_log:
                task_log.fail(str(e))
                try:
                    task_log.save()
                except Exception:
                    pass
            return {
                "success": False,
                "markdown": "",
                "error": str(e)
            }
    
    async def generate_stream(
        self,
        topic: str,
        article_type: str = "tutorial",
        target_audience: str = "intermediate",
        target_length: str = "medium",
        source_material: str = None
    ):
        """
        æµå¼ç”Ÿæˆåšå®¢ (å¼‚æ­¥ç”Ÿæˆå™¨)
        
        Args:
            topic: æŠ€æœ¯ä¸»é¢˜
            article_type: æ–‡ç« ç±»å‹
            target_audience: ç›®æ ‡å—ä¼—
            target_length: ç›®æ ‡é•¿åº¦
            source_material: å‚è€ƒèµ„æ–™
            
        Yields:
            ç”Ÿæˆè¿›åº¦å’Œä¸­é—´ç»“æœ
        """
        if self.app is None:
            self.compile()
        
        initial_state = create_initial_state(
            topic=topic,
            article_type=article_type,
            target_audience=target_audience,
            target_length=target_length,
            source_material=source_material
        )

        # 102.10 è¿ç§»ï¼šè®¾ç½®è¿½è¸ª ID
        initial_state["trace_id"] = str(uuid.uuid4())[:8]

        config = {"configurable": {"thread_id": f"blog_{topic}"}}
        for event in self.app.stream(initial_state, config):
            for node_name, state in event.items():
                yield {
                    "stage": node_name,
                    "state": state
                }
