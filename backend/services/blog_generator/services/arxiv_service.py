"""
arXiv æœç´¢æœåŠ¡ - å­¦æœ¯è®ºæ–‡æœç´¢
"""

import logging
import requests
import xml.etree.ElementTree as ET
from typing import Dict, Any, List, Optional
from urllib.parse import quote

logger = logging.getLogger(__name__)

# å…¨å±€ arXiv æœåŠ¡å®ä¾‹
_arxiv_service: Optional['ArxivService'] = None


class ArxivService:
    """
    arXiv æœç´¢æœåŠ¡ - ç”¨äºæœç´¢å­¦æœ¯è®ºæ–‡
    API æ–‡æ¡£: https://info.arxiv.org/help/api/basics.html
    """
    
    BASE_URL = "https://export.arxiv.org/api/query"
    
    def __init__(self):
        """åˆå§‹åŒ– arXiv æœåŠ¡"""
        pass
    
    def is_available(self) -> bool:
        """æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨ï¼ˆarXiv API å…è´¹æ— éœ€ Keyï¼‰"""
        return True
    
    def search(self, query: str, max_results: int = 5) -> Dict[str, Any]:
        """
        æœç´¢ arXiv è®ºæ–‡
        
        Args:
            query: æœç´¢å…³é”®è¯ï¼ˆè‹±æ–‡æ•ˆæœæ›´å¥½ï¼‰
            max_results: æœ€å¤§ç»“æœæ•°
            
        Returns:
            {
                'success': True/False,
                'results': [...],
                'summary': '...',
                'error': '...'
            }
        """
        try:
            logger.info(f"ğŸ”¬ arXiv æœç´¢: {query}")
            
            # æ„å»ºè¯·æ±‚å‚æ•°
            params = {
                'search_query': f'all:{query}',
                'start': 0,
                'max_results': min(max_results, 20),
                'sortBy': 'relevance',
                'sortOrder': 'descending'
            }
            
            response = requests.get(self.BASE_URL, params=params, timeout=30)
            response.raise_for_status()
            
            # è§£æ XML å“åº”
            results = self._parse_response(response.text)
            
            logger.info(f"ğŸ”¬ arXiv æœç´¢å®Œæˆï¼Œè·å– {len(results)} ç¯‡è®ºæ–‡")
            
            return {
                'success': True,
                'results': results,
                'summary': self._generate_summary(results),
                'error': None,
                'source': 'arxiv'
            }
            
        except Exception as e:
            logger.error(f"arXiv æœç´¢å¤±è´¥: {e}")
            return {
                'success': False,
                'results': [],
                'summary': '',
                'error': str(e),
                'source': 'arxiv'
            }
    
    def _parse_response(self, xml_text: str) -> List[Dict[str, Any]]:
        """è§£æ arXiv API XML å“åº”"""
        results = []
        
        # è§£æ XML
        root = ET.fromstring(xml_text)
        
        # arXiv ä½¿ç”¨ Atom å‘½åç©ºé—´
        ns = {
            'atom': 'http://www.w3.org/2005/Atom',
            'arxiv': 'http://arxiv.org/schemas/atom'
        }
        
        for entry in root.findall('atom:entry', ns):
            try:
                # æå–è®ºæ–‡ä¿¡æ¯
                title = entry.find('atom:title', ns)
                summary = entry.find('atom:summary', ns)
                published = entry.find('atom:published', ns)
                link = entry.find("atom:link[@type='text/html']", ns)
                if link is None:
                    link = entry.find("atom:link[@rel='alternate']", ns)
                
                # æå–ä½œè€…
                authors = []
                for author in entry.findall('atom:author', ns):
                    name = author.find('atom:name', ns)
                    if name is not None and name.text:
                        authors.append(name.text)
                
                # æå– arXiv ID
                arxiv_id = entry.find('atom:id', ns)
                arxiv_id_text = ''
                if arxiv_id is not None and arxiv_id.text:
                    # ä» URL ä¸­æå– IDï¼Œå¦‚ http://arxiv.org/abs/2401.12345
                    arxiv_id_text = arxiv_id.text.split('/')[-1]
                
                results.append({
                    'title': title.text.strip().replace('\n', ' ') if title is not None and title.text else '',
                    'url': link.get('href') if link is not None else '',
                    'content': summary.text.strip().replace('\n', ' ')[:1500] if summary is not None and summary.text else '',
                    'source': 'arXiv',
                    'publish_date': published.text[:10] if published is not None and published.text else '',
                    'authors': ', '.join(authors[:3]) + ('...' if len(authors) > 3 else ''),
                    'arxiv_id': arxiv_id_text
                })
                
            except Exception as e:
                logger.warning(f"è§£æ arXiv entry å¤±è´¥: {e}")
                continue
        
        return results
    
    def _generate_summary(self, results: List[Dict[str, Any]]) -> str:
        """ä»æœç´¢ç»“æœç”Ÿæˆæ‘˜è¦"""
        if not results:
            return ''
        
        summary_parts = []
        for i, item in enumerate(results, 1):
            title = item.get('title', '')
            content = item.get('content', '')[:500]
            arxiv_id = item.get('arxiv_id', '')
            authors = item.get('authors', '')
            
            summary_parts.append(
                f"[è®ºæ–‡ {i}] {title}\n"
                f"arXiv: {arxiv_id} | ä½œè€…: {authors}\n"
                f"æ‘˜è¦: {content}"
            )
        
        return '\n\n'.join(summary_parts)


def init_arxiv_service() -> ArxivService:
    """åˆå§‹åŒ– arXiv æœåŠ¡"""
    global _arxiv_service
    _arxiv_service = ArxivService()
    logger.info("arXiv æœç´¢æœåŠ¡å·²åˆå§‹åŒ–")
    return _arxiv_service


def get_arxiv_service() -> Optional[ArxivService]:
    """è·å– arXiv æœåŠ¡å®ä¾‹"""
    global _arxiv_service
    if _arxiv_service is None:
        _arxiv_service = ArxivService()
    return _arxiv_service
